{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def scrape():\n",
    "    # Initialize PyMongo to work with MongoDBs\n",
    "    conn = 'mongodb://localhost:27017'\n",
    "    client = pymongo.MongoClient(conn)\n",
    "\n",
    "    # Define database and collection\n",
    "    db = client.mars_db\n",
    "    collection = db.items\n",
    "    \n",
    "    # Set up Splinter\n",
    "    executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "    # Visit redplanetscience.com for latest news article\n",
    "\n",
    "    url = \"https://redplanetscience.com\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "\n",
    "    # Get the latest news article\n",
    "    news = soup.find('div', class_= 'list_text')\n",
    "\n",
    "    title = news.find('div', class_= 'content_title').text\n",
    "    desc = news.find('div', class_= 'article_teaser_body').text\n",
    "\n",
    "\n",
    "    # Visit spaceimages-mars.com for feature image\n",
    "\n",
    "    url2 = \"https://spaceimages-mars.com/\"\n",
    "\n",
    "    browser.visit(url2)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "\n",
    "    relative_image_path = soup.find_all('img')[1]['src']\n",
    "\n",
    "    featured_image = url2 + relative_image_path\n",
    "\n",
    "\n",
    "    # Visit https://galaxyfacts-mars.com for Mars vs earth comparison\n",
    "\n",
    "    table = pd.read_html('https://galaxyfacts-mars.com/')\n",
    "\n",
    "    mars_facts = table[0]\n",
    "    \n",
    "    mars_facts_html = mars_facts.to_html()\n",
    "\n",
    "\n",
    "\n",
    "    # Visit https://marshemispheres.com/ for hemispheres of Mars\n",
    "\n",
    "    url3 = 'https://marshemispheres.com/'\n",
    "\n",
    "    browser.visit(url3)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    relative_image_path = soup.find_all('img', class_='thumb')\n",
    "\n",
    "\n",
    "    hemisphere_dict = []\n",
    "\n",
    "    for x in relative_image_path:\n",
    "\n",
    "        JArray2 = {}\n",
    "        JArray2[\"title\"]= x['alt']\n",
    "        JArray2[\"img_url\"]= url3+x['src']\n",
    "        hemisphere_dict.append(JArray2)\n",
    "\n",
    "    data = {\n",
    "        'news_title': title,\n",
    "        'news_description': desc,\n",
    "        'featured_image': featured_image,\n",
    "        'mars_facts': mars_facts,\n",
    "        'hemisphere_dict':hemisphere_dict\n",
    "    }\n",
    "    \n",
    "    collection.replace_one({}, data, upsert=True)\n",
    "    \n",
    "    browser.quit()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
